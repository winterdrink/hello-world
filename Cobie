
%% directory setup
clear
datadir = '/Users/byeolkim/Dropbox/summerintern_2020/data';
savename = fullfile(datadir, 'pico_dat.mat');
load(savename);

%% Convolution 
% Magnify by using convolution
conv_circle =  [0 0 0 1 1 1 1 0 0 0;
                0 0 1 1 1 1 1 1 0 0;
                0 1 1 1 1 1 1 1 1 0;
                1 1 1 1 1 1 1 1 1 1;
                1 1 1 1 1 1 1 1 1 1;
                1 1 1 1 1 1 1 1 1 1;
                0 1 1 1 1 1 1 1 1 0;
                0 0 1 1 1 1 1 1 0 0;
                0 0 0 1 1 1 1 0 0 0];
          
           
%% example data 
% body_data = body_dat{1}{5,1};
% clim = max([max(max(body_data)) abs(min(min(body_data)))]);
% % body_data = body_data + clim * body_white_binary; 
% 
% figure;
% subplot(1,2,1);
% imagesc(body_data, [-clim clim]);
% c = [33,102,172;103,169,207;209,229,240;247,247,247;...
%     253,219,199;239,138,98;178,24,43]/255;
% colormap(c);
% colorbar
% 
% subplot(1,2,2);
% body_data_2 = conv2(body_data, conv_circle, 'same');
% clim = max([max(max(body_data_2)) abs(min(min(body_data_2)))]);
% imagesc(body_data_2, [-clim clim]);
% set(gcf, 'position', [449 1 832 624], 'color', 'w');

% dat = fmri_data(fullfile(datadir, 'fastmarker_self_unthresh.nii'));
% dat = fmri_data(fullfile(datadir, 'fastmarker_self_unthresh_mpfc_only.nii'));
% orthviews(dat);
%%
bodysz = [537, 180];
clear *_all;

% integrate activity and deactivity map
for subj_i = 1:numel(body_dat)
    for trial_i = 1:42
        % red
        act = body_dat{subj_i}{trial_i,1};
        if isequal(size(act), bodysz)
            act_conv = double(conv2(act, conv_circle, 'same')>0);
        else
            act_conv = NaN(bodysz);
        end
        
        % blue
        deact = body_dat{subj_i}{trial_i,2};
        if isequal(size(deact), bodysz)
            deact_conv = double(conv2(deact, conv_circle, 'same')>0);
        else
            deact_conv = NaN(bodysz);
        end
        
        % blur with gaussian kernel
        act_deact = imgaussfilt(act_conv-deact_conv,3);
        % filter the out part of body
        act_deact_all{subj_i}(:,trial_i) = act_deact(body_white_binary);
    end
end

%% quartile of 5 dimension survey data 
% dat에 bodymap 넣었고, Y에 score 

for dim_i = 1:5
    dat{dim_i} = fmri_data;
    
    for subj_i = 1:numel(body_dat)
        score = ratings{dim_i}(:,subj_i);
        
        % divide the survey data to quartile
        level_idx = zeros(size(score));
        level_idx(score< prctile(score, 25)) = 1;
        level_idx(score>=prctile(score, 25) & score<prctile(score, 50)) = 2;
        level_idx(score>=prctile(score, 50) & score<prctile(score, 75)) = 3;
        level_idx(score>=prctile(score, 75)) = 4;
        
        for j = 1:4
            % mean of the survey data in each quartile 
            dat{dim_i}.Y(4*(subj_i-1)+j,1) = mean(score(level_idx == j));
            try
                % mean of the bodymap in each quartile
                dat{dim_i}.dat(:,4*(subj_i-1)+j) = mean(act_deact_all{subj_i}(:,level_idx == j),2);
            catch
                dat{dim_i}.dat = mean(act_deact_all{subj_i}(:,level_idx == j),2);
            end
        end        
    end    
end

for i = 1:5
    % index of subject number(j)
    whfolds{i} = repmat(1:numel(act_deact_all), 4, 1);
    whfolds{i} = whfolds{i}(:);
    
    % deal with the empty body map at some trial
    dat{i}.Y(isnan(dat{i}.dat(1,:))) = [];      % survey
    whfolds{i}(isnan(dat{i}.dat(1,:))) = [];    % subject index
    dat{i}.dat(:,isnan(dat{i}.dat(1,:))) = [];  % bodymap
end


%% divide train data and test data
train_id = 1:30;
test_id = 31:46;
% dat_train : i가 1일 때 valence 1개, whfolds_train도 1
% dat에 열이 각 참가자의 qutile로 들어감, 43914 by 183 바디맵 벡터라이즈한 게 4만개, 이것도 component가 될 수 있음
% ismember 하면 1-30까지는 1, 그 이후는 0일 것
% size(dat()i).dat(:,ismember(wh~) 하면 120 by로 됨
% dat_train 120
% 

for i = 1:5
    dat_train{i} = dat{i};              % data of train set
    whfolds_train{i} = whfolds{i};      % subject index for train set
    
    dat_train{i}.dat = dat{i}.dat(:,ismember(whfolds{i}, train_id)); % body map
    dat_train{i}.Y = dat{i}.Y(ismember(whfolds{i}, train_id));      % survey data
    whfolds_train{i} = whfolds{i}(ismember(whfolds{i}, train_id));
    
    dat_test{i} = dat{i};               % data of test set
    whfolds_test{i} = whfolds{i};       % subject index for test set
    
    dat_test{i}.dat = dat{i}.dat(:,ismember(whfolds{i}, test_id));  % body map
    dat_test{i}.Y = dat{i}.Y(ismember(whfolds{i}, test_id));        % survey data
    whfolds_test{i} = whfolds{i}(ismember(whfolds{i}, test_id));
end

%% PCR with reduced number of components - using train data
% j는 뭐냐면, 얘가 컴포넌트 수, 컴포넌트 몇개로 학습할건가
% dat_train
% 쓸 알고리즘 이름을 넣으면 되고
% nfolds, n개 덩어리로 만들어서 한 개 빼놓고 하고 etc
% whfolds_train{1}에 30개 들어가 있을 것
% num of components : component 몇개로 뽑고 싶은지 정해줄 수 있음
% 바디맵 행 숫자 4만 개보다 더 많을 수 없음, 너무 많은 컴포넌트는 의미가 없음, PCA는 dimension을 줄이기 위해 하는 것
% 데이터는 많고 component는 적을수록 좋은 결과


for i = 1:5 % dimensions, valence, self, etc
    for j = 2:15 
        disp('========================================================');
        fprintf('Working on the component %02d/%02d, model %d/%d\n', j, 20, i, 5);
        disp('========================================================');
        [cverr, stats_train{i}{j}, optout] = predict(dat_train{i}, 'algorithm_name', 'cv_pcr', 'nfolds', whfolds_train{i}, 'error_type', 'mse',  'numcomponents', j);
    end
end

% 1은 비어있고 15까지 1by15일거고, stats_train{1}{2} 하면 y fit에 나오는 게 예측값, Y가 실제값, predic_outcome_R : .47 굉장히 잘 나온 것!

for i = 1
for j = 2:15
por(i,j) =stats_train{i}{j}.pred_outcome_r;
end
subplot(1,5,i);
plot(por(i,:));
end

% 이렇게 보면 0-15까지 플랏으로 볼 수 있음
% 2개로도 잘 된다면 2개만으로 결과가 나온다니! 와 2개만 있는데 나온다고?의 양가적 감정..
% 추세를 보여주는 플랏, x축 컴포넌트 2-15일 때 y축 performance(2개일 때 제일 잘하잖아?!)
% valence에서 2개 컴포넌트일 때 performance .4742


%% save data and results
savedir = fullfile(fastprojectdir, 'data', 'analysis_results');
savename = fullfile(savedir, 'pico_200903_body_prediction_data.mat');
save(savename, 'dat_train', 'dat_test', 'whfolds_train', 'whfolds_test', 'stats_train', '-v7.3');

%% load training results
savedir = fullfile(fastprojectdir, 'data', 'analysis_results');
savename = fullfile(savedir, 'pico_200903_body_prediction_data.mat');
load(savename)

%% prediction performance 
% 참가자마다 correlation을 본 것
% y는 예측 데이터, x는 실제 rating, 이 간의 r을 보여주는 각각의 선을 칼라맵 해서 양수 빨간색, 음수 파란색으로 하면 이 모델의 performance 직관적으로 볼 수 있음

clear r max_ncomp;

for i = 1:5         % survey dimension
    for j = 2:15   % the number of components
        
              % real survey data(mean) & predicted survey value
        y_yfit = [stats_train{i}{j}.Y, stats_train{i}{j}.yfit]; 
        
        kk = 0;
        for subj_i = unique(whfolds_train{i})'
            kk = kk+1;
            rr = corr(y_yfit(whfolds_train{i} == subj_i,:));    % correlation btw real & predicted within subject and mean it, 모든 참가자 통틀어
            within_sub_r_train{i}(kk,j-1) = rr(1,2);                             % r = 42(subject)x14(case of component) double, 한 사람씩, 30명, 2-15까지 14, 30 by 14 
        end
        z = corr(y_yfit);
        across_sub_r(i,j) = z(1,2);         % correlation across subject, it's lower than 'r', within mean값이랑 또 다름, 경향은 유지될 것
    end
    
    [max_r(i,1), max_ncomp(i,1)] = max(mean(within_sub_r_train{i})); 
end

% 경향 확인, 비교해보자
figure; plot(across_sub_r(2:end);
hold on; plot(mean(within_sub_r_train{i});

% 결과는 둘 다 2 or 3에서 가장 performance 좋음


% checking perfomance of each component number
% 고오급 코딩 cellfun
% cell이 여러 개 있을 수 있음 1*n cell, {} {} {}, e.g. within_sub_r_train에 1-5까지 dimensions 다 들어가 있을 때!
% 이 셀에 cellfun(@mean, cellname, 'UniformOutput', false);
% 하면 각 within_sub의 dimensions 평균 내줌

a = cellfun(@mean, within_sub_r_train, 'UniformOutput', false);  % a is same as r.
a = cat(1,a{:})';                               % change to double(14x5) from cell

% 누가 어느 dimensions인지 구별해서 예쁘게 그려줘
figure;     % x axis = the number of components. y axis = r.
plot(a, 'o-'); 
% plot(mean(a,2))
names = {'valence', 'self-relevance', 'time', 'vividness', 'safety-threat'};
legend([names 'max'],  'Location','NorthEastOutside');

% 가장 큰 수행이 몇이니?
max_r
max_ncomp = max_ncomp' + 1
max(across_sub_r') 
% max_r = 
% 0.4746    0.5739    0.0354    0.6638    0.3602
% max_ncomp = 3 % 가장 큰 수행 보이는 component 갯수는 몇개니?
% max(across_sub_r') = 0.4742

for i=1:5 
sss = within_sub_r_train{i}(:, max_ncomp(i));
[~,idx] = sort(sss, 'descend');
best_train_sub(i) = idx(1);
end
clear sss
% 10    27     5    26    49

%% Compare testing performance between the number of components

% other_output이 weight!
% other_output을 dat(실제 테스트하고 싶은 데이터)에 matrix 곱 한 것
% 이 결과는 yfit 즉 예측한 값이 됨

clear r_test max_r_test
for i = 1:5
    for j = 2:15 %max_ncomp(i);
        % real survey data (mean) & predicted survey value= model(1x63303)*bodymap(63303°ø120)
        y_yfit = [dat_test{i}.Y, (stats_train{i}{j}.other_output{1}'*dat_test{i}.dat)'];
        
        kk = 0;
        for subj_i = unique(whfolds_test{i})'
            kk = kk + 1;
            [rr,pp] = corr(y_yfit(whfolds_test{i} == subj_i,:));
            r_test{i}(kk,j) = rr(1,2);
            p_test{i}(kk,j) = pp(1,2);
        end
        
        z = corr(y_yfit);                   % correlation within subject
        across_sub_r(i,j) = z(1,2);         % correlation across subject, it's lower than 'r', within mean값, z(1,2)는 .3986, 꽤 잘 되는 것
    end
    %         mdl{i} = fitlm(y_yfit(:,1),y_yfit(:,2));    % ??
    [max_r_test(i,1), max_ncomp_test(i,1)] = max(mean(r_test{i}));
end

% r_test 16명
% 참가자 간 correlation은 .39, 참가자 마다 구해서 평균낸건 .3388
% 30명 정도의 데이터로 해본 바디맵 prediction!


% figure to compare cases of # components
a = cellfun(@mean, r_test, 'UniformOutput', false);
a = cat(1,a{:})';
figure;
plot(a, 'o-'); 
hold on; 
scatter(max_ncomp_test, diag(a(max_ncomp_test,:)), 30, 'k', 'filled');
legend([names 'max'],  'Location','NorthEastOutside');

best_test_sub = [find(r_test{1}(:,max_ncomp_test(1))==max(r_test{1}(:,max_ncomp_test(1)))),...
    find(r_test{2}(:,max_ncomp_test(2))==max(r_test{2}(:,max_ncomp_test(2)))),...
    find(r_test{3}(:,max_ncomp_test(3))==max(r_test{3}(:,max_ncomp_test(3)))),...
    find(r_test{4}(:,max_ncomp_test(4))==max(r_test{4}(:,max_ncomp_test(4)))),...
    find(r_test{5}(:,max_ncomp_test(5))==max(r_test{5}(:,max_ncomp_test(5))))];

% component number which is best in the training set. 
for z = 1:5
    r_bestcomp_train(z) = mean(r_test{z}(:,max_ncomp(z)));  
end

max_r_test
max_ncomp_test
max(across_sub_r')
% max_r_test =
% 0.5283    0.6102    0.1697    0.6821    0.3937
% max_ncomp_test = 
% 7 12 4 6 12

% if we choose the best # component of training, 
% r_bestcomp_train = 0.5179    0.6102    0.0491    0.6118    0.3478

% best_test_sub = 
% 25    24    11    18     8

%% visualize the model and save the figure

figdir = fullfile(fastprojectdir, 'figures');

% color code
load 'colormap_colorbrewer_wani.mat';

% pick up the data of a specific component for each dimension
for i = 1:5
    stats_max{i} = stats_train{i}{max_ncomp(i)}; 
end

% idx = find(body_white_binary>0);

figure;
for i = 1:5
    subplot(1,5,i);
    body_data = NaN(size(body_white_binary));
    weights{i} = stats_max{i}.weight_obj.dat;       % [63303°ø1 double] comes from 'stats_train'
    
    body_data(idx) = weights{i}(:,1);       % filter inner part of body
    clim = max([max(max(body_data)) abs(min(min(body_data)))]);
    imagesc(body_data, [-clim clim]);
    
%     c = [33,102,172;103,169,207;209,229,240;247,247,247;
%         253,219,199;239,138,98;178,24,43]/256;
%     colormap(c);
    colormap(col11_from_colorbrewer);
    colorbar;
    
%     set(gcf, 'color', 'w', 'position', [ 560   322   274   626])  % one map
    set(gcf, 'color', 'w', 'position', [441         322        2120         835])    % 5 maps
    axis off
    set(gca, 'fontsize', 18)
    
%     savename = fullfile(figdir, [names{i} '_onemap.pdf']);
%     pagesetup(gcf);
%     saveas(gcf, savename);
%     
%     pagesetup(gcf);
%     saveas(gcf, savename); 
end

%     savename = fullfile(figdir, 'bodymodel_1031_abs.pdf');
%     pagesetup(gcf);
%     saveas(gcf, savename);
%     
%     pagesetup(gcf);
%     saveas(gcf, savename); 


%%


%% Word cloud - each subject
% word cloud for just predicted score
names = {'valence', 'self-relevance', 'safety-threat', 'vividness', 'time'};
subplot_num = [1 4 2 5 3];  
words = get_var(D, {'word_eng'}, 'conditional', {'eventname', 'view'});
w = words(jth,:,:);

% 1 - dot product
figure('position',[1,1,1500,800]);
for subj_i = train_id(best_train_sub)'
    for i = [1 2 5 4 3]
        j = max_ncomp(i);
        word_temp = w(subj_i,:);    % english
        %         word_temp = w_kr(subj_i,:); % korean
        
        word = string(word_temp');
        
        body_temp = act_deact_all{subj_i};
        
        pred = (stats_train{i}{j}.other_output{1}'*body_temp)';
        pred2 = (pred-min(pred))/(max(pred)-min(pred));   % normalization
        
        subplot(2,3,subplot_num(i))
        wordcloud(word,pred2);
        title(names{i})
    end
    saveas(gcf, fullfile(pwd, ['1101_wordcloud_' num2str(subj_i) '.png']));

end
% close


%% 1101 poster
% color1 = [33,102,172; 103,169,207;209,229,240;
%     253,219,199;239,138,98;178,24,43;
%     254,217,142; 254,153,41; 217,95,14; 153,52,4]/256;  % red-blue & orange

color = [215,48,39; 252,141,89; 254,224,144; 255,255,191; 224,243,248;145,191,219; 69,117,180;
224,240,197; 242 205 190; 228,248,192; 236,227,203; 224,207,215; 216 135 201; 225,31,159]/256;

sss = [10 27 58 6 22];
% 1 - dot product
for  i = 1:5 % train_id([10, 27 52 26 22])'
%     figure('position',[1,1,1500,800]);
        subj_i = sss(i);
%     for i = [1 2 5 4 3]
        figure('position',[1,1,1270,1000]);    % one by one figure
        j = max_ncomp(i);
        word_temp = w(subj_i,:);
        word = string(word_temp');
        
        body_temp = act_deact_all{subj_i};
        
        pred = (stats_train{i}{j}.other_output{1}'*body_temp)';
        if mod(i,2)
            pred_abs = abs(pred);
        else 
            pred_abs = pred;
        end
        pred_abs = (pred_abs-min(pred_abs))/(max(pred_abs)-min(pred_abs));   % normalization
        
        level_idx = zeros(numel(word),1);
        if mod(i,2)
%             level_idx(pred<= -0.7) = 1;
%             level_idx(pred>-0.8 & pred<=0.4) = 2;
%             level_idx(pred>0.4 & pred<=0) = 3;
%             level_idx(pred>0 & pred<=0.4) = 4;
%             level_idx(pred>0.4 & pred<=0.7) = 5;
%             level_idx(pred>=0.7) = 6;
            level_idx(pred<= prctile(pred, 14)) = 1;
            level_idx(pred>prctile(pred, 14) & pred<=prctile(pred, 28)) = 2;
            level_idx(pred>prctile(pred, 28) & pred<=prctile(pred, 50)) = 3;
            level_idx(pred>prctile(pred, 50) & pred<=prctile(pred, 70)) = 4;
            level_idx(pred>prctile(pred, 70) & pred<=prctile(pred, 80)) = 5;
            level_idx(pred>prctile(pred, 80) & pred<=prctile(pred, 90)) = 6;
            level_idx(pred>=prctile(pred, 90)) = 7;
        else
            level_idx(pred_abs<= prctile(pred_abs, 14)) = 8;
            level_idx(pred_abs>prctile(pred_abs, 14) & pred_abs<=prctile(pred_abs, 28)) = 9;
            level_idx(pred_abs>prctile(pred_abs, 28) & pred_abs<=prctile(pred_abs, 42)) = 10;
            level_idx(pred_abs>prctile(pred_abs, 42) & pred_abs<=prctile(pred_abs, 56)) = 11;
            level_idx(pred_abs>prctile(pred_abs, 56) & pred_abs<=prctile(pred_abs, 80)) = 12;
            level_idx(pred_abs>prctile(pred_abs, 80) & pred_abs<=prctile(pred_abs, 95)) = 13;
            level_idx(pred_abs>=prctile(pred_abs, 95)) = 14;
        end
        
%         subplot(2,3,subplot_num(i))

        h = wordcloud(word,pred_abs);
        h.Color = color(level_idx,:);
%         title(names{i})

        savename = fullfile(pwd, sprintf('%s.pdf',names{i}));
        pagesetup(gcf);
        saveas(gcf, savename);
        
        pagesetup(gcf);
        saveas(gcf, savename);
        %     end
end
% close all

